import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum as spark_sum, round as spark_round
from tabulate import tabulate
from pyspark.sql.functions import isnan, when, count
from pyspark.sql.types import NumericType
from pandas import read_csv

# === 1. Ğ¡Ñ‚Ğ²Ğ¾Ñ€ÑÑ”Ğ¼Ğ¾ SparkSession ===
spark = (SparkSession.builder.appName("Spark Data Analysis Task").getOrCreate())

# === 2. Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ CSV-Ñ„Ğ°Ğ¹Ğ»Ñ–Ğ² ===
users = spark.read.option("header", True).option("inferSchema", True).csv(r"C:\Project\MasterSc\Date_Engineering\HW\data\users.csv")
purchases = spark.read.option("header", True).option("inferSchema", True).csv(r"C:\Project\MasterSc\Date_Engineering\HW\data\purchases.csv")
products = spark.read.option("header", True).option("inferSchema", True).csv(r"C:\Project\MasterSc\Date_Engineering\HW\data\products.csv")

print()
print('================================== Ğ”ĞĞĞ† ĞšĞĞ Ğ˜Ğ¡Ğ¢Ğ£Ğ’ĞĞ§Ğ†Ğ’ ================================')
users.show(5)

print()
print('================================== Ğ”ĞĞĞ† ĞŸĞ Ğ ĞŸĞĞšĞ£ĞŸĞšĞ˜ =================================')
purchases.show(5)

print()
print('============================== Ğ†ĞĞ¤ĞĞ ĞœĞĞ¦Ğ†Ğ¯ ĞŸĞ Ğ ĞŸĞ ĞĞ”Ğ£ĞšĞ¢Ğ˜ ==============================')
products.show(5)


# === 2.1. ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ”Ğ¼Ğ¾ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ñ– Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ ===

def count_missing(df, name):
    cols_expr = []
    for c in df.columns:
        # ÑĞºÑ‰Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ° Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ°, Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ÑÑ”Ğ¼Ğ¾ Ñ– isnan(), Ñ– isNull()
        if isinstance(df.schema[c].dataType, NumericType):
            cols_expr.append(count(when(col(c).isNull() | isnan(c), c)).alias(c))
        else:
            cols_expr.append(count(when(col(c).isNull(), c)).alias(c))

    missing_count = df.select(cols_expr)
    total_missing = missing_count.collect()[0].asDict()
    total_rows = df.count()

    print(f"\nğŸ” ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ñ– Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ñƒ DataFrame '{name}': (ÑƒÑÑŒĞ¾Ğ³Ğ¾ Ñ€ÑĞ´ĞºÑ–Ğ²: {total_rows})")
    for column, count_nulls in total_missing.items():
        if count_nulls > 0:
            print(f"  - {column}: {count_nulls}")
    if all(v == 0 for v in total_missing.values()):
        print("  âœ… ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¸Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½ÑŒ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾!")

print()
print('============================== ĞŸĞ ĞĞŸĞ£Ğ©Ğ•ĞĞ† Ğ—ĞĞĞ§Ğ•ĞĞĞ¯ Ğ£ DATAFRAME ==============================')
count_missing(users, "users")
count_missing(purchases, "purchases")
count_missing(products, "products")

# === 3. ĞÑ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ñ Ğ´Ğ°Ğ½Ğ¸Ñ… ===
users = users.dropna()
purchases = purchases.dropna()
products = products.dropna()

print()
print('============================== Ğ”ĞĞĞ† ĞŸĞ†Ğ¡Ğ›Ğ¯ ĞĞ§Ğ˜Ğ©Ğ•ĞĞĞ¯ ==============================')
count_missing(users, "users")
count_missing(purchases, "purchases")
count_missing(products, "products")

# === 4. ĞĞ±â€™Ñ”Ğ´Ğ½Ğ°Ğ½Ğ½Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†ÑŒ ===
df = (purchases.join(users, on="user_id", how="inner").join(products, on="product_id", how="inner"))

# === 5. Ğ”Ğ¾Ğ´Ğ°Ñ”Ğ¼Ğ¾ ÑÑ‚Ğ¾Ğ²Ğ¿ĞµÑ†ÑŒ Ñ–Ğ· Ğ·Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ¾Ñ ÑÑƒĞ¼Ğ¾Ñ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ ===
df = df.withColumn("total_price", col("quantity") * col("price"))

# === 6. Ğ—Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ° ÑÑƒĞ¼Ğ° Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–ÑÑ… ===
total_by_category = (df.groupBy("category").agg(spark_round(spark_sum("total_price"), 2).alias("total_sum"))
                     .orderBy(col("total_sum").desc()))

# === 7. Ğ”Ğ°Ğ½Ñ– Ğ¿Ğ¾ Ğ¼Ğ¾Ğ»Ğ¾Ğ´Ñ– 18â€“25 Ñ€Ğ¾ĞºÑ–Ğ² ===
df_young = df.filter((col("age") >= 18) & (col("age") <= 25))

sum_young_by_category = (df_young.groupBy("category").agg(spark_round(spark_sum("total_price"), 2)
                                                          .alias("sum_young"))
                         .orderBy(col("sum_young").desc()))

# === 8. Ğ§Ğ°ÑÑ‚ĞºĞ° Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº Ñƒ Ğ²Ñ–Ğ´ÑĞ¾Ñ‚ĞºĞ°Ñ… ===
total_young_sum = sum_young_by_category.agg(spark_sum("sum_young").alias("total_young")).collect()[0]["total_young"]

share_young = (
    sum_young_by_category.withColumn("share_percent", spark_round(col("sum_young") / total_young_sum * 100, 2))
    .orderBy(col("share_percent").desc())
)

top3 = share_young.limit(3)

# === 9. ĞŸĞµÑ€ĞµÑ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ Ğ½Ğ° Pandas Ğ´Ğ»Ñ Ğ³Ğ°Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¸Ğ²Ğ¾Ğ´Ñƒ ===
total_by_category_pd = total_by_category.toPandas()
sum_young_by_category_pd = sum_young_by_category.toPandas()
share_young_pd = share_young.toPandas()
top3_pd = top3.toPandas()

# === 10. Ğ’Ğ¸Ğ²Ñ–Ğ´ ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾ Ñ‡ĞµÑ€ĞµĞ· tabulate ===
print()
print('\n============================== Ğ—ĞĞ“ĞĞ›Ğ¬ĞĞ Ğ¡Ğ£ĞœĞ ĞŸĞĞšĞ£ĞŸĞĞš Ğ—Ğ ĞšĞĞ¢Ğ•Ğ“ĞĞ Ğ†Ğ¯ĞœĞ˜ ==============================')
print(tabulate(total_by_category_pd, headers='keys', tablefmt='fancy_grid', showindex=False))

print()
print('\n============================== Ğ¡Ğ£ĞœĞ ĞŸĞĞšĞ£ĞŸĞĞš (18â€“25 Ğ ĞĞšĞ†Ğ’): ==============================')
print(tabulate(sum_young_by_category_pd, headers='keys', tablefmt='fancy_grid', showindex=False))

print()
print(
    '\n============================== Ğ§ĞĞ¡Ğ¢ĞšĞ ĞŸĞĞšĞ£ĞŸĞĞš (18â€“25 Ğ ĞĞšĞ†Ğ’) Ğ£ % Ğ’Ğ†Ğ” Ğ—ĞĞ“ĞĞ›Ğ¬ĞĞ˜Ğ¥ Ğ’Ğ˜Ğ¢Ğ ĞĞ¢: ==============================')
print(tabulate(share_young_pd, headers='keys', tablefmt='fancy_grid', showindex=False))

print()
print('\n============================== Ğ¢ĞĞŸ-3 ĞšĞĞ¢Ğ•Ğ“ĞĞ Ğ†Ğ‡ Ğ¡Ğ•Ğ Ğ•Ğ” ĞœĞĞ›ĞĞ”Ğ† (18â€“25): ==============================')
print(tabulate(top3_pd, headers='keys', tablefmt='fancy_grid', showindex=False))

# === 11. Ğ—Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ½Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ² Ñƒ Ñ„Ğ°Ğ¹Ğ»Ğ¸ ===
os.makedirs("output", exist_ok=True)

total_by_category_pd.to_csv("output/total_by_category.csv", index=False)
sum_young_by_category_pd.to_csv("output/sum_young_by_category.csv", index=False)
share_young_pd.to_csv("output/share_young.csv", index=False)
top3_pd.to_csv("output/top3_categories.csv", index=False)

print()
print('\n============================== Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ˜ Ğ—Ğ‘Ğ•Ğ Ğ•Ğ–Ğ•ĞĞ Ğ’ ĞŸĞĞŸĞšĞ£ "output/" ==============================')

# === 12. Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ ÑĞµÑÑ–Ñ— ===
spark.stop()
